import torch as tr
import numpy as np
from .network import NeuralNetworkPyTorch
from torch.autograd import Variable
from utils import LinePrinter
from .utils import maybeCuda, maybeCpu
from inspect import signature

class RecurrentNeuralNetworkPyTorch(NeuralNetworkPyTorch):
	def __str__(self):
		return "General recurrent neural network architecture. Update __str__ in your model for more details when " + \
			"using summary."

	# Basic method that does a forward phase for one epoch given a generator modified for recurrent neural networks. It
	#  can apply a step of optimizer or not.
	# @param[in] generator Object used to get a batch of data and labels at each step
	# @param[in] stepsPerEpoch How many items to be generated by the generator
	# @param[in] metrics A dictionary containing the metrics over which the epoch is run
	# @param[in] optimize If true, then the optimizer is also called after each iteration
	# @return The mean metrics over all the steps.
	def run_one_epoch(self, generator, stepsPerEpoch, callbacks=[], optimize=False, printMessage=False, debug=False):
		assert "Loss" in self.metrics.keys(), "At least one metric is required and Loss must be in them"
		assert not self.criterion is None, "Expected a criterion/loss to be set before training/testing."
		metricResults = {metric : 0 for metric in self.metrics.keys()}
		linePrinter = LinePrinter()

		for i, (npData, npLabels) in enumerate(generator):
			trData = tr.from_numpy(npData)
			trLabels = tr.from_numpy(npLabels)

			# Each timestep is sent manually (instead of letting pytorch do the loop itself). The shape of trData
			#  should be: MB x T x dataShape. This is needed since there may be other network components that do not
			#  with time series (such as Conv2Ds), and we take the pressure off the model so implement just the simple
			#  T=1 case.
			# The sequence size is extracted from the returned data. Thus, the data INSIDE the minibatch must have
			#  identical w.r.t timestamps. If the data timestamps is different, they must be padded inside the
			#  generator to be identical.
			sequenceSize = npData.shape[1]

			# Do the first timestamp separate, so we can infer the result shape
			data = maybeCuda(Variable(trData[:, 0]))
			labels = maybeCuda(Variable(trLabels[:, 0]))
			# For the hiden states, use a list of Nones, expecting the signature to be: (x, hidden1, ..., hiddenN)
			initialHiddenState = [None] * (len(signature(self.forward).parameters) - 1)
			results, hiddenState = self.forward(data, *initialHiddenState)
			npResult = maybeCpu(results.data).numpy()
			npResults = np.zeros((npData.shape[0], npData.shape[1], *npResult.shape[1 : ]))
			npResults[:, 0] = npResult
			loss = self.criterion(results, labels)

			# Then the next N - 1 timesteps are done assuming that the shape of the result doensn't change.
			for t in range(1, sequenceSize):
				# Slicing the data as: MB x 1 x dataShape, sending each sequence one by one.
				data = maybeCuda(Variable(trData[:, t]))
				labels = maybeCuda(Variable(trLabels[:, t]))

				results, hiddenState = self.forward(data, hiddenState)
				result = maybeCpu(results.data).numpy()
				npResults[:, t] = result

				loss += self.criterion(results, labels)
			npLoss = maybeCpu(loss.data).numpy()
			if debug:
				print("\nLoss: %2.6f" % (npLoss))

			if optimize:
				self.optimizer.zero_grad()
				loss.backward()
				self.optimizer.step()

			# Iteration callbacks are called here (i.e. for plotting results!)
			callbackArgs = {
				"data" : npData,
				"labels" : npLabels,
				"results" : npResults,
				"loss" : npLoss,
				"iteration" : i,
				"numIterations" : stepsPerEpoch,
				"hiddenState" : hiddenState
			}
			for callback in callbacks:
				callback(**callbackArgs)

			for metric in self.metrics:
				metricResults[metric] += self.metrics[metric](npResults, npLabels, loss=npLoss)

			if printMessage:
				message = "Iteration: %d/%d." % (i + 1, stepsPerEpoch)
				for metric in metricResults:
					message += " %s: %2.2f." % (metric, metricResults[metric] / (i + 1))
				linePrinter.print(message)

			del data, labels
			if i == stepsPerEpoch - 1:
				break

		for metric in metricResults:
			metricResults[metric] /= stepsPerEpoch
		return metricResults