import numpy as np
import h5py
from .dataset_reader import DatasetReader

# Structure:
# "train"
# 	"noseq"
#  		"rgb"
# 		"ground_truth_fine"
# 		"flownet2s"
#		...
# 	"seq_5"
#		"rgb"
#		"flownet2s"
#		...
#	"seq_1"
#	...
# "validation"
# ...

# CityScapes Reader class, used with the data already converted in h5py format.
# @param[in] datasetPath Path the the cityscapes_v2.h5 file
# @param[in] imageShape The shape of the images. Must coincide with what type of data is required.
# @param[in] labelShape The shape of the labels (depths).
# @param[in] transforms A list of transformations (augmentations) that are applied to both images and labels
# @param[in] dataDimensions A list of all type of inputs that are to be generated by this reader. Supported values
#  are: "rgb", "depth", "ground_truth_fine", "rgb_first_frame"
# @param[optional] semanticTransform The type of transformation to be applied for semantic data. Only valid if
#  "ground_truth_fine" is used in dataDimensions.
class CityScapesReader(DatasetReader):
	def __init__(self, datasetPath, imageShape, labelShape, transforms=["none"], normalization="standardization", \
		dataDimensions=["rgb"], sequentialData=False, semanticTransform=None):
		super().__init__(datasetPath, imageShape, labelShape, transforms, normalization)
		self.dataDimensions = dataDimensions
		self.sequentialData = sequentialData
		self.semanticTransform = semanticTransform
		self.setup()

	def setup(self):
		self.dataset = h5py.File(self.datasetPath, "r")

		# Validty checks for data dimensions.
		for data in self.dataDimensions:
			assert data in ("rgb", "depth", "flownet2s", "ground_truth_fine", "rgb_first_frame", "deeplabv3"), \
				"Got %s" % (data)
			if self.sequentialData == True:
				assert not data == "ground_truth_fine", "Semantic data is not available for sequential dataset"
				assert not data == "rgb_first_frame", "RGB First frame is not available for sequential dataset"
				# Only skipFrames=5 is supported now

		if "ground_truth_fine" in self.dataDimensions or "deeplabv3" in self.dataDimensions:
			assert self.semanticTransform in ("default", "foreground-background", "none")
			if self.semanticTransform == "default":
				self.prepareSemantic = self.semanticDefault
			elif self.semanticTransform == "foreground-background":
				self.prepareSemantic = self.semanticFGBG
			elif self.semanticTransform == "none":
				self.prepareSemantic = lambda x : np.expand_dims(x, axis=-1)

		# Only skipFrames=5 is supported now
		if self.sequentialData:
			self.numData = {Type : len(self.dataset[Type]["seq_5"]["rgb"]) for Type in ("test", "train", "validation")}
		else:
			self.numData = {Type : len(self.dataset[Type]["noseq"]["rgb"]) for Type in ("test", "train", "validation")}

		# These values are directly computed on the training set of the sequential data (superset of original dataset).
		# They are duplicated for sequential and non-sequential data to avoid unnecessary code.
		self.means = {
			"rgb" : [74.96715607296854, 84.3387139353354, 73.62945761147961],
			"rgb_first_frame" : [74.96715607296854, 84.3387139353354, 73.62945761147961],
			"depth" : 8277.619363028218,
			"flownet2s" : [-0.6396361, 5.553444],
			"ground_truth_fine" : 0,
			"deeplabv3" : 0
		}

		self.stds = {
			"rgb" : [49.65527668307159, 50.01892939272212, 49.67332749250472],
			"rgb_first_frame" : [49.65527668307159, 50.01892939272212, 49.67332749250472],
			"depth" : 6569.138224069467,
			"flownet2s" : [32.508713, 15.168872],
			"ground_truth_fine" : 1,
			"deeplabv3" : 1
		}

		self.maximums = {
			"rgb" : [255, 255, 255],
			"rgb_first_frame" : [255, 255, 255],
			"depth" : 32257,
			"flownet2s" : [278.29926, 225.12384],
			"ground_truth_fine" : 1,
			"deeplabv3" : 1
		}

		self.minimums = {
			"rgb" : [0, 0, 0],
			"rgb_first_frame" : [0, 0, 0],
			"depth" : 0,
			"flownet2s" : [-494.61987, -166.98322],
			"ground_truth_fine" : 0,
			"deeplabv3" : 0
		}

		self.numDimensions = {
			"rgb" : 3,
			"depth": 1,
			"flownet2s" : 2,
			"ground_truth_fine" : 1,
			"deeplabv3" : 1,
			"rgb_first_frame" : 3
		}

		requiredDimensions = 0
		for data in self.dataDimensions:
			requiredDimensions += self.numDimensions[data]
		assert requiredDimensions == self.dataShape[-1], "Expected: numDimensions: %s. Got imageShape: %s for: %s" % \
			(requiredDimensions, self.dataShape, self.dataDimensions)

		print(("[CityScapes Images Reader] Setup complete. Num data: Train: %d, Test: %d, Validation: %d. " + \
			"Images shape: %s. Depths shape: %s. Required data: %s. Sequential: %s. Semantic type: %s. " + \
			"Normalization type: %s") % \
			(self.numData["train"], self.numData["test"], self.numData["validation"], self.dataShape, \
			self.labelShape, self.dataDimensions, self.sequentialData, self.semanticTransform, self.normalization))

	def semanticDefault(self, images):
		newImages = np.expand_dims(images, axis=-1)
		return newImages / 33

	def semanticFGBG(self, images):
		newImage = np.ones((*images.shape, 1), dtype=np.float32)
		labels = {
			"sky" : np.where(images == 23),
			"buildings" : np.where(images == 11),
			"logo" : np.where(images == 1),
			"road" : np.where(images == 7),
			"sidewalk" : np.where(images == 22),
			"sidewalk2": np.where(images == 8),
			"trees" : np.where(images == 21)
		}

		for key in labels:
			newImage[labels[key]] = 0
		return newImage

	def iterate_once(self, type, miniBatchSize):
		assert type in ("train", "test", "validation")
		augmenter = self.dataAugmenter if type == "train" else self.validationAugmenter
		thisData = self.dataset[type]["seq_5"] if self.sequentialData else self.dataset[type]["noseq"]

		# One iteration in this method accounts for all transforms at once
		for i in range(self.getNumIterations(type, miniBatchSize, accountTransforms=False)):
			startIndex = i * miniBatchSize
			endIndex = min((i + 1) * miniBatchSize, self.numData[type])
			assert startIndex < endIndex, "startIndex < endIndex. Got values: %d %d" % (startIndex, endIndex)

			depths = self.normalizer(thisData["depth"][startIndex : endIndex], "depth")
			images = []
			for dim in self.dataDimensions:
				item = self.normalizer(thisData[dim][startIndex : endIndex], dim)
				if dim in ("ground_truth_fine", "deeplabv3"):
					item = self.prepareSemantic(item)
				images.append(item)
			images = np.concatenate(images, axis=3)

			# Apply each transform
			for augImages, augDepths in augmenter.applyTransforms(images, depths, interpolationType="bilinear"):
				yield augImages, augDepths
				del augImages, augDepths
